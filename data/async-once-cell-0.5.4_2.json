{
    "level": "Warning",
    "analyzer": "UnsafeDestructor",
    "op_type": null,
    "description": "unsafe block detected in drop",
    "file": "async-once-cell-0.5.4/src/lib.rs",
    "start_line": 407,
    "start_col": 1,
    "end_line": 407,
    "end_col": 37,
    "code_snippet": "impl<'a> Drop for QuickInitGuard<'a> {\n    fn drop(&mut self) {\n        // When our QuickInitGuard was created, Inner::state was changed to QINIT_BIT.  If it is\n        // either unchanged or has changed back to that value, we can finish on the fast path.\n        let fast_target = if self.ready { READY_BIT } else { NEW };\n        if self\n            .inner\n            .state\n            .compare_exchange(QINIT_BIT, fast_target, Ordering::Release, Ordering::Relaxed)\n            .is_ok()\n        {\n            // Because the exchange succeeded, we know there are no active QueueRefs and so no\n            // wakers need to be woken.  If self.ready is true, the Release ordering pairs with\n            // the Acquire on another thread's access to state to check READY_BIT.\n\n            if self.ready {\n                // It's possible (though unlikely) that someone created the queue but abandoned\n                // their QueueRef before we finished our poll, resulting in us not observing\n                // them.  No wakes are needed in this case because there are no waiting tasks,\n                // but we should still clean up the allocation.\n                let queue = self.inner.queue.swap(ptr::null_mut(), Ordering::Relaxed);\n                if !queue.is_null() {\n                    // Synchronize with both the fetch_sub that lowered the refcount and the\n                    // queue initialization.\n                    core::sync::atomic::fence(Ordering::Acquire);\n                    // Safety: we observed no active QueueRefs, and queue is only used by\n                    // guard-holders.  Due to the swap, we are the only one who is freeing this\n                    // particular queue.\n                    unsafe {\n                        drop(Box::from_raw(queue));\n                    }\n                }\n            }\n            return;\n        }\n\n        // Slow path: get a guard, create the QueueHead we should have been holding, then drop it\n        // so that the tasks are woken as intended.  This is needed regardless of if we succeeded\n        // or not - either waiters need to run init themselves, or they need to read the value we\n        // set.\n        //\n        // The guard is guaranteed to have been created with no QueueHead available because\n        // QINIT_BIT is still set.\n        let waiter = self.inner.initialize(false).expect(\"Got a QuickInitGuard in slow init\");\n        let guard = waiter.guard.expect(\"No guard available even without polling\");\n\n        // Safety: the guard holds a place on the waiter list, and we know READY_BIT was not yet\n        // set when Inner::initialize was called, so the queue must be present.  It will remain\n        // valid until guard is dropped.\n        debug_assert!(!guard.queue.is_null(), \"Queue must not be NULL when READY_BIT is not set\");\n        let queue = unsafe { &*guard.queue };\n\n        with_lock(&queue.wakers, |lock| {\n            // Creating a QueueHead requires that the Mutex contain Some.  While this is likely\n            // already true, it is not guaranteed because the first concurrent thread might have\n            // been preempted before it was able to start its first QueueWaiter::poll call.  Ensure\n            // that nobody else can grab the QueueHead between when we release QINIT_BIT and when\n            // our QueueHead is dropped.\n            lock.get_or_insert_with(Vec::new);\n\n            // We must clear QINIT_BIT, which will allow someone else to take the head position\n            // once we drop it.\n            //\n            // If our initialization was successful, we also need to set READY_BIT.  These\n            // operations can be combined because we know the current state of both bits (only\n            // QINIT_BIT is set) and because READY_BIT == 2 * QINIT_BIT.\n            //\n            // Ordering for QINIT_BIT is handled by the Mutex, but ordering for READY_BIT is not;\n            // it needs Release ordering to ensure that the UnsafeCell's value is visible prior to\n            // that bit being observed as set by other threads.\n            let prev_state = if self.ready {\n                self.inner.state.fetch_add(QINIT_BIT, Ordering::Release)\n            } else {\n                self.inner.state.fetch_sub(QINIT_BIT, Ordering::Relaxed)\n            };\n            debug_assert_eq!(\n                prev_state & (QINIT_BIT | READY_BIT),\n                QINIT_BIT,\n                \"Invalid state during QuickInitGuard drop\"\n            );\n        });\n\n        // Safety: we just took the head position\n        drop(QueueHead { guard })\n    }\n}"
}