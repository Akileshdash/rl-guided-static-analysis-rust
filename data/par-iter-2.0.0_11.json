{
    "level": "Warning",
    "analyzer": "UnsafeDataflow",
    "op_type": "ReadFlow/Transmute",
    "description": "Potential unsafe dataflow issue in `slice::sort::partition_in_blocks`",
    "file": "par-iter-2.0.0/src/slice/sort.rs",
    "start_line": 334,
    "start_col": 1,
    "end_line": 611,
    "end_col": 2,
    "code_snippet": "fn partition_in_blocks<T, F>(v: &mut [T], pivot: &T, is_less: &F) -> usize\nwhere\n    F: Fn(&T, &T) -> bool,\n{\n    // Number of elements in a typical block.\n    const BLOCK: usize = 128;\n\n    // The partitioning algorithm repeats the following steps until completion:\n    //\n    // 1. Trace a block from the left side to identify elements greater than or\n    //    equal to the pivot.\n    // 2. Trace a block from the right side to identify elements smaller than the\n    //    pivot.\n    // 3. Exchange the identified elements between the left and right side.\n    //\n    // We keep the following variables for a block of elements:\n    //\n    // 1. `block` - Number of elements in the block.\n    // 2. `start` - Start pointer into the `offsets` array.\n    // 3. `end` - End pointer into the `offsets` array.\n    // 4. `offsets` - Indices of out-of-order elements within the block.\n\n    // The current block on the left side (from `l` to `l.add(block_l)`).\n    let mut l = v.as_mut_ptr();\n    let mut block_l = BLOCK;\n    let mut start_l = ptr::null_mut();\n    let mut end_l = ptr::null_mut();\n    let mut offsets_l = [MaybeUninit::<u8>::uninit(); BLOCK];\n\n    // The current block on the right side (from `r.sub(block_r)` to `r`).\n    // SAFETY: The documentation for .add() specifically mention that\n    // `vec.as_ptr().add(vec.len())` is always safe\n    let mut r = unsafe { l.add(v.len()) };\n    let mut block_r = BLOCK;\n    let mut start_r = ptr::null_mut();\n    let mut end_r = ptr::null_mut();\n    let mut offsets_r = [MaybeUninit::<u8>::uninit(); BLOCK];\n\n    // FIXME: When we get VLAs, try creating one array of length `min(v.len(), 2 *\n    // BLOCK)` rather than two fixed-size arrays of length `BLOCK`. VLAs might\n    // be more cache-efficient.\n\n    // Returns the number of elements between pointers `l` (inclusive) and `r`\n    // (exclusive).\n    fn width<T>(l: *mut T, r: *mut T) -> usize {\n        assert!(mem::size_of::<T>() > 0);\n        // FIXME: this should *likely* use `offset_from`, but more\n        // investigation is needed (including running tests in miri).\n        (r as usize - l as usize) / mem::size_of::<T>()\n    }\n\n    loop {\n        // We are done with partitioning block-by-block when `l` and `r` get very close.\n        // Then we do some patch-up work in order to partition the remaining\n        // elements in between.\n        let is_done = width(l, r) <= 2 * BLOCK;\n\n        if is_done {\n            // Number of remaining elements (still not compared to the pivot).\n            let mut rem = width(l, r);\n            if start_l < end_l || start_r < end_r {\n                rem -= BLOCK;\n            }\n\n            // Adjust block sizes so that the left and right block don't overlap, but get\n            // perfectly aligned to cover the whole remaining gap.\n            if start_l < end_l {\n                block_r = rem;\n            } else if start_r < end_r {\n                block_l = rem;\n            } else {\n                // There were the same number of elements to switch on both blocks during the\n                // last iteration, so there are no remaining elements on either\n                // block. Cover the remaining items with roughly equally-sized\n                // blocks.\n                block_l = rem / 2;\n                block_r = rem - block_l;\n            }\n            debug_assert!(block_l <= BLOCK && block_r <= BLOCK);\n            debug_assert!(width(l, r) == block_l + block_r);\n        }\n\n        if start_l == end_l {\n            // Trace `block_l` elements from the left side.\n            start_l = offsets_l.as_mut_ptr() as *mut u8;\n            end_l = start_l;\n            let mut elem = l;\n\n            for i in 0..block_l {\n                // SAFETY: The unsafety operations below involve the usage of the `offset`.\n                //         According to the conditions required by the function, we satisfy them\n                // because:\n                //         1. `offsets_l` is stack-allocated, and thus considered separate\n                //            allocated object.\n                //         2. The function `is_less` returns a `bool`. Casting a `bool` will\n                //            never overflow `isize`.\n                //         3. We have guaranteed that `block_l` will be `<= BLOCK`. Plus,\n                //            `end_l` was initially set to the begin pointer of `offsets_` which\n                //            was declared on the stack. Thus, we know that even in the worst\n                //            case (all invocations of `is_less` returns false) we will only be\n                //            at most 1 byte pass the end.\n                //        Another unsafety operation here is dereferencing `elem`.\n                //        However, `elem` was initially the begin pointer to the slice which is\n                // always valid.\n                unsafe {\n                    // Branchless comparison.\n                    *end_l = i as u8;\n                    end_l = end_l.add(!is_less(&*elem, pivot) as usize);\n                    elem = elem.add(1);\n                }\n            }\n        }\n\n        if start_r == end_r {\n            // Trace `block_r` elements from the right side.\n            start_r = offsets_r.as_mut_ptr() as *mut u8;\n            end_r = start_r;\n            let mut elem = r;\n\n            for i in 0..block_r {\n                // SAFETY: The unsafety operations below involve the usage of the `offset`.\n                //         According to the conditions required by the function, we satisfy them\n                // because:\n                //         1. `offsets_r` is stack-allocated, and thus considered separate\n                //            allocated object.\n                //         2. The function `is_less` returns a `bool`. Casting a `bool` will\n                //            never overflow `isize`.\n                //         3. We have guaranteed that `block_r` will be `<= BLOCK`. Plus,\n                //            `end_r` was initially set to the begin pointer of `offsets_` which\n                //            was declared on the stack. Thus, we know that even in the worst\n                //            case (all invocations of `is_less` returns true) we will only be\n                //            at most 1 byte pass the end.\n                //        Another unsafety operation here is dereferencing `elem`.\n                //        However, `elem` was initially `1 * sizeof(T)` past the end and we\n                // decrement it by `1 * sizeof(T)` before accessing it.\n                //        Plus, `block_r` was asserted to be less than `BLOCK` and `elem` will\n                // therefore at most be pointing to the beginning of the slice.\n                unsafe {\n                    // Branchless comparison.\n                    elem = elem.sub(1);\n                    *end_r = i as u8;\n                    end_r = end_r.add(is_less(&*elem, pivot) as usize);\n                }\n            }\n        }\n\n        // Number of out-of-order elements to swap between the left and right side.\n        let count = cmp::min(width(start_l, end_l), width(start_r, end_r));\n\n        if count > 0 {\n            macro_rules! left {\n                () => {\n                    l.add(usize::from(*start_l))\n                };\n            }\n            macro_rules! right {\n                () => {\n                    r.sub(usize::from(*start_r) + 1)\n                };\n            }\n\n            // Instead of swapping one pair at the time, it is more efficient to perform a\n            // cyclic permutation. This is not strictly equivalent to swapping,\n            // but produces a similar result using fewer memory operations.\n\n            // SAFETY: The use of `ptr::read` is valid because there is at least one element\n            // in both `offsets_l` and `offsets_r`, so `left!` is a valid\n            // pointer to read from.\n            //\n            // The uses of `left!` involve calls to `offset` on `l`, which points to the\n            // beginning of `v`. All the offsets pointed-to by `start_l` are at most\n            // `block_l`, so these `offset` calls are safe as all reads are\n            // within the block. The same argument applies for the uses of\n            // `right!`.\n            //\n            // The calls to `start_l.offset` are valid because there are at most `count-1`\n            // of them, plus the final one at the end of the unsafe block, where\n            // `count` is the minimum number of collected offsets in `offsets_l`\n            // and `offsets_r`, so there is no risk of there not being enough\n            // elements. The same reasoning applies to the calls to `start_r.offset`.\n            //\n            // The calls to `copy_nonoverlapping` are safe because `left!` and `right!` are\n            // guaranteed not to overlap, and are valid because of the reasoning\n            // above.\n            unsafe {\n                let tmp = ptr::read(left!());\n                ptr::copy_nonoverlapping(right!(), left!(), 1);\n\n                for _ in 1..count {\n                    start_l = start_l.add(1);\n                    ptr::copy_nonoverlapping(left!(), right!(), 1);\n                    start_r = start_r.add(1);\n                    ptr::copy_nonoverlapping(right!(), left!(), 1);\n                }\n\n                ptr::copy_nonoverlapping(&tmp, right!(), 1);\n                mem::forget(tmp);\n                start_l = start_l.add(1);\n                start_r = start_r.add(1);\n            }\n        }\n\n        if start_l == end_l {\n            // All out-of-order elements in the left block were moved. Move to the next\n            // block.\n\n            // block-width-guarantee\n            // SAFETY: if `!is_done` then the slice width is guaranteed to be at least\n            // `2*BLOCK` wide. There are at most `BLOCK` elements in `offsets_l`\n            // because of its size, so the `offset` operation is\n            // safe. Otherwise, the debug assertions in the `is_done` case guarantee that\n            // `width(l, r) == block_l + block_r`, namely, that the block sizes have been\n            // adjusted to account for the smaller number of remaining elements.\n            l = unsafe { l.add(block_l) };\n        }\n\n        if start_r == end_r {\n            // All out-of-order elements in the right block were moved. Move to the previous\n            // block.\n\n            // SAFETY: Same argument as [block-width-guarantee]. Either this is a full block\n            // `2*BLOCK`-wide, or `block_r` has been adjusted for the last\n            // handful of elements.\n            r = unsafe { r.sub(block_r) };\n        }\n\n        if is_done {\n            break;\n        }\n    }\n\n    // All that remains now is at most one block (either the left or the right) with\n    // out-of-order elements that need to be moved. Such remaining elements can\n    // be simply shifted to the end within their block.\n\n    if start_l < end_l {\n        // The left block remains.\n        // Move its remaining out-of-order elements to the far right.\n        debug_assert_eq!(width(l, r), block_l);\n        while start_l < end_l {\n            // remaining-elements-safety\n            // SAFETY: while the loop condition holds there are still elements in\n            // `offsets_l`, so it is safe to point `end_l` to the previous\n            // element.\n            //\n            // The `ptr::swap` is safe if both its arguments are valid for reads and writes:\n            //  - Per the debug assert above, the distance between `l` and `r` is `block_l`\n            //    elements, so there can be at most `block_l` remaining offsets between\n            //    `start_l` and `end_l`. This means `r` will be moved at most `block_l`\n            //    steps back, which makes the `r.offset` calls valid (at that point `l ==\n            //    r`).\n            //  - `offsets_l` contains valid offsets into `v` collected during the\n            //    partitioning of the last block, so the `l.offset` calls are valid.\n            unsafe {\n                end_l = end_l.sub(1);\n                ptr::swap(l.add(usize::from(*end_l)), r.sub(1));\n                r = r.sub(1);\n            }\n        }\n        width(v.as_mut_ptr(), r)\n    } else if start_r < end_r {\n        // The right block remains.\n        // Move its remaining out-of-order elements to the far left.\n        debug_assert_eq!(width(l, r), block_r);\n        while start_r < end_r {\n            // SAFETY: See the reasoning in [remaining-elements-safety].\n            unsafe {\n                end_r = end_r.sub(1);\n                ptr::swap(l, r.sub(usize::from(*end_r) + 1));\n                l = l.add(1);\n            }\n        }\n        width(v.as_mut_ptr(), l)\n    } else {\n        // Nothing else to do, we're done.\n        width(v.as_mut_ptr(), l)\n    }\n}"
}