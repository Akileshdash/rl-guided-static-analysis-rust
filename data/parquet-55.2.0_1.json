{
    "level": "Info",
    "analyzer": "UnsafeDataflow",
    "op_type": "Transmute",
    "description": "Potential unsafe dataflow issue in `<arrow::array_reader::list_array::ListArrayReader<OffsetSize> as arrow::array_reader::ArrayReader>::consume_batch`",
    "file": "parquet-55.2.0/src/arrow/array_reader/list_array.rs",
    "start_line": 84,
    "start_col": 5,
    "end_line": 231,
    "end_col": 6,
    "code_snippet": "fn consume_batch(&mut self) -> Result<ArrayRef> {\n        let next_batch_array = self.item_reader.consume_batch()?;\n        if next_batch_array.is_empty() {\n            return Ok(new_empty_array(&self.data_type));\n        }\n\n        let def_levels = self\n            .item_reader\n            .get_def_levels()\n            .ok_or_else(|| general_err!(\"item_reader def levels are None.\"))?;\n\n        let rep_levels = self\n            .item_reader\n            .get_rep_levels()\n            .ok_or_else(|| general_err!(\"item_reader rep levels are None.\"))?;\n\n        if OffsetSize::from_usize(next_batch_array.len()).is_none() {\n            return Err(general_err!(\n                \"offset of {} would overflow list array\",\n                next_batch_array.len()\n            ));\n        }\n\n        if !rep_levels.is_empty() && rep_levels[0] != 0 {\n            // This implies either the source data was invalid, or the leaf column\n            // reader did not correctly delimit semantic records\n            return Err(general_err!(\"first repetition level of batch must be 0\"));\n        }\n\n        // A non-nullable list has a single definition level indicating if the list is empty\n        //\n        // A nullable list has two definition levels associated with it:\n        //\n        // The first identifies if the list is null\n        // The second identifies if the list is empty\n        //\n        // The child data returned above is padded with a value for each not-fully defined level.\n        // Therefore null and empty lists will correspond to a value in the child array.\n        //\n        // Whilst nulls may have a non-zero slice in the offsets array, empty lists must\n        // be of zero length. As a result we MUST filter out values corresponding to empty\n        // lists, and for consistency we do the same for nulls.\n\n        // The output offsets for the computed ListArray\n        let mut list_offsets: Vec<OffsetSize> = Vec::with_capacity(next_batch_array.len() + 1);\n\n        // The validity mask of the computed ListArray if nullable\n        let mut validity = self\n            .nullable\n            .then(|| BooleanBufferBuilder::new(next_batch_array.len()));\n\n        // The offset into the filtered child data of the current level being considered\n        let mut cur_offset = 0;\n\n        // Identifies the start of a run of values to copy from the source child data\n        let mut filter_start = None;\n\n        // The number of child values skipped due to empty lists or nulls\n        let mut skipped = 0;\n\n        // Builder used to construct the filtered child data, skipping empty lists and nulls\n        let data = next_batch_array.to_data();\n        let mut child_data_builder =\n            MutableArrayData::new(vec![&data], false, next_batch_array.len());\n\n        def_levels.iter().zip(rep_levels).try_for_each(|(d, r)| {\n            match r.cmp(&self.rep_level) {\n                Ordering::Greater => {\n                    // Repetition level greater than current => already handled by inner array\n                    if *d < self.def_level {\n                        return Err(general_err!(\n                            \"Encountered repetition level too large for definition level\"\n                        ));\n                    }\n                }\n                Ordering::Equal => {\n                    // New value in the current list\n                    cur_offset += 1;\n                }\n                Ordering::Less => {\n                    // Create new array slice\n                    // Already checked that this cannot overflow\n                    list_offsets.push(OffsetSize::from_usize(cur_offset).unwrap());\n\n                    if *d >= self.def_level {\n                        // Fully defined value\n\n                        // Record current offset if it is None\n                        filter_start.get_or_insert(cur_offset + skipped);\n\n                        cur_offset += 1;\n\n                        if let Some(validity) = validity.as_mut() {\n                            validity.append(true)\n                        }\n                    } else {\n                        // Flush the current slice of child values if any\n                        if let Some(start) = filter_start.take() {\n                            child_data_builder.extend(0, start, cur_offset + skipped);\n                        }\n\n                        if let Some(validity) = validity.as_mut() {\n                            // Valid if empty list\n                            validity.append(*d + 1 == self.def_level)\n                        }\n\n                        skipped += 1;\n                    }\n                }\n            }\n            Ok(())\n        })?;\n\n        list_offsets.push(OffsetSize::from_usize(cur_offset).unwrap());\n\n        let child_data = if skipped == 0 {\n            // No filtered values - can reuse original array\n            next_batch_array.to_data()\n        } else {\n            // One or more filtered values - must build new array\n            if let Some(start) = filter_start.take() {\n                child_data_builder.extend(0, start, cur_offset + skipped)\n            }\n\n            child_data_builder.freeze()\n        };\n\n        if cur_offset != child_data.len() {\n            return Err(general_err!(\"Failed to reconstruct list from level data\"));\n        }\n\n        let value_offsets = Buffer::from(list_offsets.to_byte_slice());\n\n        let mut data_builder = ArrayData::builder(self.get_data_type().clone())\n            .len(list_offsets.len() - 1)\n            .add_buffer(value_offsets)\n            .add_child_data(child_data);\n\n        if let Some(builder) = validity {\n            assert_eq!(builder.len(), list_offsets.len() - 1);\n            data_builder = data_builder.null_bit_buffer(Some(builder.into()))\n        }\n\n        let list_data = unsafe { data_builder.build_unchecked() };\n\n        let result_array = GenericListArray::<OffsetSize>::from(list_data);\n        Ok(Arc::new(result_array))\n    }"
}