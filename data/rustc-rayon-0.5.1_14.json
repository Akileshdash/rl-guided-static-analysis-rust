{
    "level": "Warning",
    "analyzer": "UnsafeDataflow",
    "op_type": "ReadFlow/Transmute",
    "description": "Potential unsafe dataflow issue in `slice::quicksort::partition_in_blocks`",
    "file": "rustc-rayon-0.5.1/src/slice/quicksort.rs",
    "start_line": 249,
    "start_col": 1,
    "end_line": 501,
    "end_col": 2,
    "code_snippet": "fn partition_in_blocks<T, F>(v: &mut [T], pivot: &T, is_less: &F) -> usize\nwhere\n    F: Fn(&T, &T) -> bool,\n{\n    // Number of elements in a typical block.\n    const BLOCK: usize = 128;\n\n    // The partitioning algorithm repeats the following steps until completion:\n    //\n    // 1. Trace a block from the left side to identify elements greater than or equal to the pivot.\n    // 2. Trace a block from the right side to identify elements smaller than the pivot.\n    // 3. Exchange the identified elements between the left and right side.\n    //\n    // We keep the following variables for a block of elements:\n    //\n    // 1. `block` - Number of elements in the block.\n    // 2. `start` - Start pointer into the `offsets` array.\n    // 3. `end` - End pointer into the `offsets` array.\n    // 4. `offsets - Indices of out-of-order elements within the block.\n\n    // The current block on the left side (from `l` to `l.add(block_l)`).\n    let mut l = v.as_mut_ptr();\n    let mut block_l = BLOCK;\n    let mut start_l = ptr::null_mut();\n    let mut end_l = ptr::null_mut();\n    let mut offsets_l = [MaybeUninit::<u8>::uninit(); BLOCK];\n\n    // The current block on the right side (from `r.sub(block_r)` to `r`).\n    // SAFETY: The documentation for .add() specifically mention that `vec.as_ptr().add(vec.len())` is always safe`\n    let mut r = unsafe { l.add(v.len()) };\n    let mut block_r = BLOCK;\n    let mut start_r = ptr::null_mut();\n    let mut end_r = ptr::null_mut();\n    let mut offsets_r = [MaybeUninit::<u8>::uninit(); BLOCK];\n\n    // FIXME: When we get VLAs, try creating one array of length `min(v.len(), 2 * BLOCK)` rather\n    // than two fixed-size arrays of length `BLOCK`. VLAs might be more cache-efficient.\n\n    // Returns the number of elements between pointers `l` (inclusive) and `r` (exclusive).\n    fn width<T>(l: *mut T, r: *mut T) -> usize {\n        assert!(mem::size_of::<T>() > 0);\n        // FIXME: this should *likely* use `offset_from`, but more\n        // investigation is needed (including running tests in miri).\n        // TODO unstable: (r.addr() - l.addr()) / mem::size_of::<T>()\n        (r as usize - l as usize) / mem::size_of::<T>()\n    }\n\n    loop {\n        // We are done with partitioning block-by-block when `l` and `r` get very close. Then we do\n        // some patch-up work in order to partition the remaining elements in between.\n        let is_done = width(l, r) <= 2 * BLOCK;\n\n        if is_done {\n            // Number of remaining elements (still not compared to the pivot).\n            let mut rem = width(l, r);\n            if start_l < end_l || start_r < end_r {\n                rem -= BLOCK;\n            }\n\n            // Adjust block sizes so that the left and right block don't overlap, but get perfectly\n            // aligned to cover the whole remaining gap.\n            if start_l < end_l {\n                block_r = rem;\n            } else if start_r < end_r {\n                block_l = rem;\n            } else {\n                // There were the same number of elements to switch on both blocks during the last\n                // iteration, so there are no remaining elements on either block. Cover the remaining\n                // items with roughly equally-sized blocks.\n                block_l = rem / 2;\n                block_r = rem - block_l;\n            }\n            debug_assert!(block_l <= BLOCK && block_r <= BLOCK);\n            debug_assert!(width(l, r) == block_l + block_r);\n        }\n\n        if start_l == end_l {\n            // Trace `block_l` elements from the left side.\n            // TODO unstable: start_l = MaybeUninit::slice_as_mut_ptr(&mut offsets_l);\n            start_l = offsets_l.as_mut_ptr() as *mut u8;\n            end_l = start_l;\n            let mut elem = l;\n\n            for i in 0..block_l {\n                // SAFETY: The unsafety operations below involve the usage of the `offset`.\n                //         According to the conditions required by the function, we satisfy them because:\n                //         1. `offsets_l` is stack-allocated, and thus considered separate allocated object.\n                //         2. The function `is_less` returns a `bool`.\n                //            Casting a `bool` will never overflow `isize`.\n                //         3. We have guaranteed that `block_l` will be `<= BLOCK`.\n                //            Plus, `end_l` was initially set to the begin pointer of `offsets_` which was declared on the stack.\n                //            Thus, we know that even in the worst case (all invocations of `is_less` returns false) we will only be at most 1 byte pass the end.\n                //        Another unsafety operation here is dereferencing `elem`.\n                //        However, `elem` was initially the begin pointer to the slice which is always valid.\n                unsafe {\n                    // Branchless comparison.\n                    *end_l = i as u8;\n                    end_l = end_l.offset(!is_less(&*elem, pivot) as isize);\n                    elem = elem.offset(1);\n                }\n            }\n        }\n\n        if start_r == end_r {\n            // Trace `block_r` elements from the right side.\n            // TODO unstable: start_r = MaybeUninit::slice_as_mut_ptr(&mut offsets_r);\n            start_r = offsets_r.as_mut_ptr() as *mut u8;\n            end_r = start_r;\n            let mut elem = r;\n\n            for i in 0..block_r {\n                // SAFETY: The unsafety operations below involve the usage of the `offset`.\n                //         According to the conditions required by the function, we satisfy them because:\n                //         1. `offsets_r` is stack-allocated, and thus considered separate allocated object.\n                //         2. The function `is_less` returns a `bool`.\n                //            Casting a `bool` will never overflow `isize`.\n                //         3. We have guaranteed that `block_r` will be `<= BLOCK`.\n                //            Plus, `end_r` was initially set to the begin pointer of `offsets_` which was declared on the stack.\n                //            Thus, we know that even in the worst case (all invocations of `is_less` returns true) we will only be at most 1 byte pass the end.\n                //        Another unsafety operation here is dereferencing `elem`.\n                //        However, `elem` was initially `1 * sizeof(T)` past the end and we decrement it by `1 * sizeof(T)` before accessing it.\n                //        Plus, `block_r` was asserted to be less than `BLOCK` and `elem` will therefore at most be pointing to the beginning of the slice.\n                unsafe {\n                    // Branchless comparison.\n                    elem = elem.offset(-1);\n                    *end_r = i as u8;\n                    end_r = end_r.offset(is_less(&*elem, pivot) as isize);\n                }\n            }\n        }\n\n        // Number of out-of-order elements to swap between the left and right side.\n        let count = cmp::min(width(start_l, end_l), width(start_r, end_r));\n\n        if count > 0 {\n            macro_rules! left {\n                () => {\n                    l.offset(*start_l as isize)\n                };\n            }\n            macro_rules! right {\n                () => {\n                    r.offset(-(*start_r as isize) - 1)\n                };\n            }\n\n            // Instead of swapping one pair at the time, it is more efficient to perform a cyclic\n            // permutation. This is not strictly equivalent to swapping, but produces a similar\n            // result using fewer memory operations.\n\n            // SAFETY: The use of `ptr::read` is valid because there is at least one element in\n            // both `offsets_l` and `offsets_r`, so `left!` is a valid pointer to read from.\n            //\n            // The uses of `left!` involve calls to `offset` on `l`, which points to the\n            // beginning of `v`. All the offsets pointed-to by `start_l` are at most `block_l`, so\n            // these `offset` calls are safe as all reads are within the block. The same argument\n            // applies for the uses of `right!`.\n            //\n            // The calls to `start_l.offset` are valid because there are at most `count-1` of them,\n            // plus the final one at the end of the unsafe block, where `count` is the minimum number\n            // of collected offsets in `offsets_l` and `offsets_r`, so there is no risk of there not\n            // being enough elements. The same reasoning applies to the calls to `start_r.offset`.\n            //\n            // The calls to `copy_nonoverlapping` are safe because `left!` and `right!` are guaranteed\n            // not to overlap, and are valid because of the reasoning above.\n            unsafe {\n                let tmp = ptr::read(left!());\n                ptr::copy_nonoverlapping(right!(), left!(), 1);\n\n                for _ in 1..count {\n                    start_l = start_l.offset(1);\n                    ptr::copy_nonoverlapping(left!(), right!(), 1);\n                    start_r = start_r.offset(1);\n                    ptr::copy_nonoverlapping(right!(), left!(), 1);\n                }\n\n                ptr::copy_nonoverlapping(&tmp, right!(), 1);\n                mem::forget(tmp);\n                start_l = start_l.offset(1);\n                start_r = start_r.offset(1);\n            }\n        }\n\n        if start_l == end_l {\n            // All out-of-order elements in the left block were moved. Move to the next block.\n\n            // block-width-guarantee\n            // SAFETY: if `!is_done` then the slice width is guaranteed to be at least `2*BLOCK` wide. There\n            // are at most `BLOCK` elements in `offsets_l` because of its size, so the `offset` operation is\n            // safe. Otherwise, the debug assertions in the `is_done` case guarantee that\n            // `width(l, r) == block_l + block_r`, namely, that the block sizes have been adjusted to account\n            // for the smaller number of remaining elements.\n            l = unsafe { l.add(block_l) };\n        }\n\n        if start_r == end_r {\n            // All out-of-order elements in the right block were moved. Move to the previous block.\n\n            // SAFETY: Same argument as [block-width-guarantee]. Either this is a full block `2*BLOCK`-wide,\n            // or `block_r` has been adjusted for the last handful of elements.\n            r = unsafe { r.offset(-(block_r as isize)) };\n        }\n\n        if is_done {\n            break;\n        }\n    }\n\n    // All that remains now is at most one block (either the left or the right) with out-of-order\n    // elements that need to be moved. Such remaining elements can be simply shifted to the end\n    // within their block.\n\n    if start_l < end_l {\n        // The left block remains.\n        // Move its remaining out-of-order elements to the far right.\n        debug_assert_eq!(width(l, r), block_l);\n        while start_l < end_l {\n            // remaining-elements-safety\n            // SAFETY: while the loop condition holds there are still elements in `offsets_l`, so it\n            // is safe to point `end_l` to the previous element.\n            //\n            // The `ptr::swap` is safe if both its arguments are valid for reads and writes:\n            //  - Per the debug assert above, the distance between `l` and `r` is `block_l`\n            //    elements, so there can be at most `block_l` remaining offsets between `start_l`\n            //    and `end_l`. This means `r` will be moved at most `block_l` steps back, which\n            //    makes the `r.offset` calls valid (at that point `l == r`).\n            //  - `offsets_l` contains valid offsets into `v` collected during the partitioning of\n            //    the last block, so the `l.offset` calls are valid.\n            unsafe {\n                end_l = end_l.offset(-1);\n                ptr::swap(l.offset(*end_l as isize), r.offset(-1));\n                r = r.offset(-1);\n            }\n        }\n        width(v.as_mut_ptr(), r)\n    } else if start_r < end_r {\n        // The right block remains.\n        // Move its remaining out-of-order elements to the far left.\n        debug_assert_eq!(width(l, r), block_r);\n        while start_r < end_r {\n            // SAFETY: See the reasoning in [remaining-elements-safety].\n            unsafe {\n                end_r = end_r.offset(-1);\n                ptr::swap(l, r.offset(-(*end_r as isize) - 1));\n                l = l.offset(1);\n            }\n        }\n        width(v.as_mut_ptr(), l)\n    } else {\n        // Nothing else to do, we're done.\n        width(v.as_mut_ptr(), l)\n    }\n}"
}