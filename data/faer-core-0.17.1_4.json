{
    "level": "Info",
    "analyzer": "UnsafeDataflow",
    "op_type": "Transmute",
    "description": "Potential unsafe dataflow issue in `sort::partition_in_blocks`",
    "file": "faer-core-0.17.1/src/sort.rs",
    "start_line": 412,
    "start_col": 1,
    "end_line": 676,
    "end_col": 2,
    "code_snippet": "unsafe fn partition_in_blocks<P: Ptr, F: FnMut(P, P) -> bool>(\n    v: P,\n    v_len: usize,\n    pivot: P,\n    is_less: &mut F,\n) -> usize {\n    // Number of elements in a typical block.\n    const BLOCK: usize = 128;\n\n    // The partitioning algorithm repeats the following steps until completion:\n    //\n    // 1. Trace a block from the left side to identify elements greater than or equal to the pivot.\n    // 2. Trace a block from the right side to identify elements smaller than the pivot.\n    // 3. Exchange the identified elements between the left and right side.\n    //\n    // We keep the following variables for a block of elements:\n    //\n    // 1. `block` - Number of elements in the block.\n    // 2. `start` - Start pointer into the `offsets` array.\n    // 3. `end` - End pointer into the `offsets` array.\n    // 4. `offsets` - Indices of out-of-order elements within the block.\n\n    // The current block on the left side (from `l` to `l.add(block_l)`).\n    let mut l = v;\n    let mut block_l = BLOCK;\n    let mut start_l = core::ptr::null_mut();\n    let mut end_l = core::ptr::null_mut();\n    let mut offsets_l = [core::mem::MaybeUninit::<u8>::uninit(); BLOCK];\n\n    // The current block on the right side (from `r.sub(block_r)` to `r`).\n    // SAFETY: The documentation for .add() specifically mention that `vec.as_ptr().add(vec.len())`\n    // is always safe\n    let mut r = unsafe { l.add(v_len) };\n    let mut block_r = BLOCK;\n    let mut start_r = core::ptr::null_mut();\n    let mut end_r = core::ptr::null_mut();\n    let mut offsets_r = [core::mem::MaybeUninit::<u8>::uninit(); BLOCK];\n\n    // FIXME: When we get VLAs, try creating one array of length `min(v.len(), 2 * BLOCK)` rather\n    // than two fixed-size arrays of length `BLOCK`. VLAs might be more cache-efficient.\n\n    // Returns the number of elements between pointers `l` (inclusive) and `r` (exclusive).\n    unsafe fn width<P: Ptr>(l: P, r: P) -> usize {\n        r.offset_from(l) as usize\n    }\n\n    loop {\n        // We are done with partitioning block-by-block when `l` and `r` get very close. Then we do\n        // some patch-up work in order to partition the remaining elements in between.\n        let is_done = width(l, r) <= 2 * BLOCK;\n\n        if is_done {\n            // Number of remaining elements (still not compared to the pivot).\n            let mut rem = width(l, r);\n            if start_l < end_l || start_r < end_r {\n                rem -= BLOCK;\n            }\n\n            // Adjust block sizes so that the left and right block don't overlap, but get perfectly\n            // aligned to cover the whole remaining gap.\n            if start_l < end_l {\n                block_r = rem;\n            } else if start_r < end_r {\n                block_l = rem;\n            } else {\n                // There were the same number of elements to switch on both blocks during the last\n                // iteration, so there are no remaining elements on either block. Cover the\n                // remaining items with roughly equally-sized blocks.\n                block_l = rem / 2;\n                block_r = rem - block_l;\n            }\n            debug_assert!(block_l <= BLOCK && block_r <= BLOCK);\n            debug_assert!(width(l, r) == block_l + block_r);\n        }\n\n        if start_l == end_l {\n            // Trace `block_l` elements from the left side.\n            start_l = offsets_l.as_mut_ptr() as *mut u8;\n            end_l = start_l;\n            let mut elem = l;\n\n            for i in 0..block_l {\n                // SAFETY: The unsafety operations below involve the usage of the `offset`.\n                //         According to the conditions required by the function, we satisfy them\n                // because:\n                //         1. `offsets_l` is stack-allocated, and thus considered separate allocated\n                //            object.\n                //         2. The function `is_less` returns a `bool`. Casting a `bool` will never\n                //            overflow `isize`.\n                //         3. We have guaranteed that `block_l` will be `<= BLOCK`. Plus, `end_l`\n                //            was initially set to the begin pointer of `offsets_` which was\n                //            declared on the stack. Thus, we know that even in the worst case (all\n                //            invocations of `is_less` returns false) we will only be at most 1 byte\n                //            pass the end.\n                //        Another unsafety operation here is dereferencing `elem`.\n                //        However, `elem` was initially the begin pointer to the slice which is\n                // always valid.\n                unsafe {\n                    // Branchless comparison.\n                    *end_l = i as u8;\n                    end_l = end_l.add(!is_less(elem, pivot) as usize);\n                    elem = elem.add(1);\n                }\n            }\n        }\n\n        if start_r == end_r {\n            // Trace `block_r` elements from the right side.\n            start_r = offsets_r.as_mut_ptr() as *mut u8;\n            end_r = start_r;\n            let mut elem = r;\n\n            for i in 0..block_r {\n                // SAFETY: The unsafety operations below involve the usage of the `offset`.\n                //         According to the conditions required by the function, we satisfy them\n                // because:\n                //         1. `offsets_r` is stack-allocated, and thus considered separate allocated\n                //            object.\n                //         2. The function `is_less` returns a `bool`. Casting a `bool` will never\n                //            overflow `isize`.\n                //         3. We have guaranteed that `block_r` will be `<= BLOCK`. Plus, `end_r`\n                //            was initially set to the begin pointer of `offsets_` which was\n                //            declared on the stack. Thus, we know that even in the worst case (all\n                //            invocations of `is_less` returns true) we will only be at most 1 byte\n                //            pass the end.\n                //        Another unsafety operation here is dereferencing `elem`.\n                //        However, `elem` was initially `1 * sizeof(T)` past the end and we\n                // decrement it by `1 * sizeof(T)` before accessing it.        Plus,\n                // `block_r` was asserted to be less than `BLOCK` and `elem` will therefore at most\n                // be pointing to the beginning of the slice.\n                unsafe {\n                    // Branchless comparison.\n                    elem = elem.sub(1);\n                    *end_r = i as u8;\n                    end_r = end_r.add(is_less(elem, pivot) as usize);\n                }\n            }\n        }\n\n        // Number of out-of-order elements to swap between the left and right side.\n        let count = Ord::min(width(start_l, end_l), width(start_r, end_r));\n\n        if count > 0 {\n            macro_rules! left {\n                () => {\n                    l.add(usize::from(*start_l))\n                };\n            }\n            macro_rules! right {\n                () => {\n                    r.sub(usize::from(*start_r) + 1)\n                };\n            }\n\n            // Instead of swapping one pair at the time, it is more efficient to perform a cyclic\n            // permutation. This is not strictly equivalent to swapping, but produces a similar\n            // result using fewer memory operations.\n\n            // SAFETY: The use of `ptr::read` is valid because there is at least one element in\n            // both `offsets_l` and `offsets_r`, so `left!` is a valid pointer to read from.\n            //\n            // The uses of `left!` involve calls to `offset` on `l`, which points to the\n            // beginning of `v`. All the offsets pointed-to by `start_l` are at most `block_l`, so\n            // these `offset` calls are safe as all reads are within the block. The same argument\n            // applies for the uses of `right!`.\n            //\n            // The calls to `start_l.offset` are valid because there are at most `count-1` of them,\n            // plus the final one at the end of the unsafe block, where `count` is the minimum\n            // number of collected offsets in `offsets_l` and `offsets_r`, so there is\n            // no risk of there not being enough elements. The same reasoning applies to\n            // the calls to `start_r.offset`.\n            //\n            // The calls to `copy_nonoverlapping` are safe because `left!` and `right!` are\n            // guaranteed not to overlap, and are valid because of the reasoning above.\n            unsafe {\n                let tmp = P::read(left!());\n                let tmp_ptr = P::get_ptr(&tmp as *const P::Item as *mut P::Item);\n                P::copy_nonoverlapping(right!(), left!(), 1);\n\n                for _ in 1..count {\n                    start_l = start_l.add(1);\n                    P::copy_nonoverlapping(left!(), right!(), 1);\n                    start_r = start_r.add(1);\n                    P::copy_nonoverlapping(right!(), left!(), 1);\n                }\n\n                P::copy_nonoverlapping(tmp_ptr, right!(), 1);\n                // core::mem::forget(tmp);\n                start_l = start_l.add(1);\n                start_r = start_r.add(1);\n            }\n        }\n\n        if start_l == end_l {\n            // All out-of-order elements in the left block were moved. Move to the next block.\n\n            // block-width-guarantee\n            // SAFETY: if `!is_done` then the slice width is guaranteed to be at least `2*BLOCK`\n            // wide. There are at most `BLOCK` elements in `offsets_l` because of its\n            // size, so the `offset` operation is safe. Otherwise, the debug assertions\n            // in the `is_done` case guarantee that `width(l, r) == block_l + block_r`,\n            // namely, that the block sizes have been adjusted to account\n            // for the smaller number of remaining elements.\n            l = unsafe { l.add(block_l) };\n        }\n\n        if start_r == end_r {\n            // All out-of-order elements in the right block were moved. Move to the previous block.\n\n            // SAFETY: Same argument as [block-width-guarantee]. Either this is a full block\n            // `2*BLOCK`-wide, or `block_r` has been adjusted for the last handful of\n            // elements.\n            r = unsafe { r.sub(block_r) };\n        }\n\n        if is_done {\n            break;\n        }\n    }\n\n    // All that remains now is at most one block (either the left or the right) with out-of-order\n    // elements that need to be moved. Such remaining elements can be simply shifted to the end\n    // within their block.\n\n    if start_l < end_l {\n        // The left block remains.\n        // Move its remaining out-of-order elements to the far right.\n        debug_assert_eq!(width(l, r), block_l);\n        while start_l < end_l {\n            // remaining-elements-safety\n            // SAFETY: while the loop condition holds there are still elements in `offsets_l`, so it\n            // is safe to point `end_l` to the previous element.\n            //\n            // The `ptr::swap` is safe if both its arguments are valid for reads and writes:\n            //  - Per the debug assert above, the distance between `l` and `r` is `block_l`\n            //    elements, so there can be at most `block_l` remaining offsets between `start_l`\n            //    and `end_l`. This means `r` will be moved at most `block_l` steps back, which\n            //    makes the `r.offset` calls valid (at that point `l == r`).\n            //  - `offsets_l` contains valid offsets into `v` collected during the partitioning of\n            //    the last block, so the `l.offset` calls are valid.\n            unsafe {\n                end_l = end_l.sub(1);\n                P::swap(l.add(usize::from(*end_l)), r.sub(1));\n                r = r.sub(1);\n            }\n        }\n        width(v, r)\n    } else if start_r < end_r {\n        // The right block remains.\n        // Move its remaining out-of-order elements to the far left.\n        debug_assert_eq!(width(l, r), block_r);\n        while start_r < end_r {\n            // SAFETY: See the reasoning in [remaining-elements-safety].\n            unsafe {\n                end_r = end_r.sub(1);\n                P::swap(l, r.sub(usize::from(*end_r) + 1));\n                l = l.add(1);\n            }\n        }\n        width(v, l)\n    } else {\n        // Nothing else to do, we're done.\n        width(v, l)\n    }\n}"
}