{
    "level": "Info",
    "analyzer": "UnsafeDataflow",
    "op_type": "Transmute",
    "description": "Potential unsafe dataflow issue in `scheduler::Scheduler::<U>::tick`",
    "file": "tokio-current-thread-0.1.7/src/scheduler.rs",
    "start_line": 212,
    "start_col": 5,
    "end_line": 344,
    "end_col": 6,
    "code_snippet": "pub fn tick(&mut self, eid: u64, enter: &mut Enter, num_futures: &AtomicUsize) -> bool {\n        let mut ret = false;\n        let tick = self.inner.tick_num.fetch_add(1, SeqCst).wrapping_add(1);\n\n        loop {\n            let node = match unsafe { self.inner.dequeue(Some(tick)) } {\n                Dequeue::Empty => {\n                    return ret;\n                }\n                Dequeue::Yield => {\n                    self.inner.unpark.unpark();\n                    return ret;\n                }\n                Dequeue::Inconsistent => {\n                    thread::yield_now();\n                    continue;\n                }\n                Dequeue::Data(node) => node,\n            };\n\n            ret = true;\n\n            debug_assert!(node != self.inner.stub());\n\n            unsafe {\n                if (*(*node).item.get()).is_none() {\n                    // The node has already been released. However, while it was\n                    // being released, another thread notified it, which\n                    // resulted in it getting pushed into the mpsc channel.\n                    //\n                    // In this case, we just decrement the ref count.\n                    let node = ptr2arc(node);\n                    assert!((*node.next_all.get()).is_null());\n                    assert!((*node.prev_all.get()).is_null());\n                    continue;\n                };\n\n                // We're going to need to be very careful if the `poll`\n                // function below panics. We need to (a) not leak memory and\n                // (b) ensure that we still don't have any use-after-frees. To\n                // manage this we do a few things:\n                //\n                // * This \"bomb\" here will call `release_node` if dropped\n                //   abnormally. That way we'll be sure the memory management\n                //   of the `node` is managed correctly.\n                //\n                // * We unlink the node from our internal queue to preemptively\n                //   assume is is complete (will return Ready or panic), in\n                //   which case we'll want to discard it regardless.\n                //\n                struct Bomb<'a, U: Unpark + 'a> {\n                    borrow: &'a mut Borrow<'a, U>,\n                    enter: &'a mut Enter,\n                    node: Option<Arc<Node<U>>>,\n                }\n\n                impl<'a, U: Unpark> Drop for Bomb<'a, U> {\n                    fn drop(&mut self) {\n                        if let Some(node) = self.node.take() {\n                            self.borrow.enter(self.enter, || release_node(node))\n                        }\n                    }\n                }\n\n                let node = self.nodes.remove(node);\n\n                let mut borrow = Borrow {\n                    id: eid,\n                    scheduler: self,\n                    num_futures,\n                };\n\n                let mut bomb = Bomb {\n                    node: Some(node),\n                    enter: enter,\n                    borrow: &mut borrow,\n                };\n\n                let mut done = false;\n\n                // Now that the bomb holds the node, create a new scope. This\n                // scope ensures that the borrow will go out of scope before we\n                // mutate the node pointer in `bomb` again\n                {\n                    let node = bomb.node.as_ref().unwrap();\n\n                    // Get a reference to the inner future. We already ensured\n                    // that the item `is_some`.\n                    let item = (*node.item.get()).as_mut().unwrap();\n\n                    // Unset queued flag... this must be done before\n                    // polling. This ensures that the item gets\n                    // rescheduled if it is notified **during** a call\n                    // to `poll`.\n                    let prev = (*node).queued.swap(false, SeqCst);\n                    assert!(prev);\n\n                    // Poll the underlying item with the appropriate `notify`\n                    // implementation. This is where a large bit of the unsafety\n                    // starts to stem from internally. The `notify` instance itself\n                    // is basically just our `Arc<Node>` and tracks the mpsc\n                    // queue of ready items.\n                    //\n                    // Critically though `Node` won't actually access `Task`, the\n                    // item, while it's floating around inside of `Task`\n                    // instances. These structs will basically just use `T` to size\n                    // the internal allocation, appropriately accessing fields and\n                    // deallocating the node if need be.\n                    let borrow = &mut *bomb.borrow;\n                    let enter = &mut *bomb.enter;\n                    let notify = Notify(bomb.node.as_ref().unwrap());\n\n                    let mut scheduled = Scheduled {\n                        task: item,\n                        notify: &notify,\n                        done: &mut done,\n                    };\n\n                    if borrow.enter(enter, || scheduled.tick()) {\n                        // we have a borrow of the Runtime, so we know it's not shut down\n                        borrow.num_futures.fetch_sub(2, SeqCst);\n                    }\n                }\n\n                if !done {\n                    // The future is not done, push it back into the \"all\n                    // node\" list.\n                    let node = bomb.node.take().unwrap();\n                    bomb.borrow.scheduler.nodes.push_back(node);\n                }\n            }\n        }\n    }"
}