{
    "level": "Info",
    "analyzer": "UnsafeDataflow",
    "op_type": "Transmute",
    "description": "Potential unsafe dataflow issue in `mem_vec::MemVec::<'a, T, A>::dedup_by`",
    "file": "memvec-0.2.0/src/mem_vec.rs",
    "start_line": 580,
    "start_col": 5,
    "end_line": 675,
    "end_col": 6,
    "code_snippet": "pub fn dedup_by<F>(&mut self, mut same_bucket: F)\n    where\n        F: FnMut(&mut T, &mut T) -> bool,\n    {\n        let len = self.len();\n        if len <= 1 {\n            return;\n        }\n\n        /* INVARIANT: vec.len() > read >= write > write-1 >= 0 */\n        struct FillGapOnDrop<'a, 'b, T: Copy, A: Memory> {\n            /* Offset of the element we want to check if it is duplicate */\n            read: usize,\n\n            /* Offset of the place where we want to place the non-duplicate\n             * when we find it. */\n            write: usize,\n\n            /* The Vec that would need correction if `same_bucket` panicked */\n            vec: &'a mut MemVec<'b, T, A>,\n        }\n\n        impl<'a, 'b, T: Copy, A: Memory> Drop for FillGapOnDrop<'a, 'b, T, A> {\n            fn drop(&mut self) {\n                /* This code gets executed when `same_bucket` panics */\n                /* SAFETY: invariant guarantees that `read - write`\n                 * and `len - read` never overflow and that the copy is always\n                 * in-bounds. */\n                unsafe {\n                    let ptr = self.vec.as_mut_ptr();\n                    let len = self.vec.len();\n\n                    /* How many items were left when `same_bucket` panicked.\n                     * Basically vec[read..].len() */\n                    let items_left = len.wrapping_sub(self.read);\n\n                    /* Pointer to first item in vec[write..write+items_left] slice */\n                    let dropped_ptr = ptr.add(self.write);\n                    /* Pointer to first item in vec[read..] slice */\n                    let valid_ptr = ptr.add(self.read);\n\n                    /* Copy `vec[read..]` to `vec[write..write+items_left]`.\n                     * The slices can overlap, so `copy_nonoverlapping` cannot be used */\n                    ptr::copy(valid_ptr, dropped_ptr, items_left);\n\n                    /* How many items have been already dropped\n                     * Basically vec[read..write].len() */\n                    let dropped = self.read.wrapping_sub(self.write);\n\n                    self.vec.set_len(len - dropped);\n                }\n            }\n        }\n\n        let mut gap = FillGapOnDrop {\n            read: 1,\n            write: 1,\n            vec: self,\n        };\n        let ptr = gap.vec.as_mut_ptr();\n\n        /* Drop items while going through Vec, it should be more efficient than\n         * doing slice partition_dedup + truncate */\n        /* SAFETY: Because of the invariant, read_ptr, prev_ptr and write_ptr\n         * are always in-bounds and read_ptr never aliases prev_ptr */\n        unsafe {\n            while gap.read < len {\n                let read_ptr = ptr.add(gap.read);\n                let prev_ptr = ptr.add(gap.write.wrapping_sub(1));\n\n                if same_bucket(&mut *read_ptr, &mut *prev_ptr) {\n                    // Increase `gap.read` now since the drop may panic.\n                    gap.read += 1;\n                    /* We have found duplicate, drop it in-place */\n                    ptr::drop_in_place(read_ptr);\n                } else {\n                    let write_ptr = ptr.add(gap.write);\n\n                    /* Because `read_ptr` can be equal to `write_ptr`, we either\n                     * have to use `copy` or conditional `copy_nonoverlapping`.\n                     * Looks like the first option is faster. */\n                    ptr::copy(read_ptr, write_ptr, 1);\n\n                    /* We have filled that place, so go further */\n                    gap.write += 1;\n                    gap.read += 1;\n                }\n            }\n\n            /* Technically we could let `gap` clean up with its Drop, but\n             * when `same_bucket` is guaranteed to not panic, this bloats a little\n             * the codegen, so we just do it manually */\n            gap.vec.set_len(gap.write);\n            core::mem::forget(gap);\n        }\n    }"
}